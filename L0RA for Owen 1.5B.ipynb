{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TT9qMTrLo-Ng"
   },
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "import nbformat, os\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "SRC = '/content/drive/MyDrive/Colab Notebooks/Untitled20.ipynb'\n",
    "DST = '/content/drive/MyDrive/colab_saves/L0RA for Owen 1.5B.ipynb'\n",
    "\n",
    "with open(SRC, 'r', encoding='utf-8') as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "\n",
    "nb.metadata.pop('widgets', None)\n",
    "for cell in nb.cells:\n",
    "    cell.metadata.pop('widgets', None)\n",
    "os.makedirs(os.path.dirname(DST), exist_ok=True)\n",
    "with open(DST, 'w', encoding='utf-8') as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "print(\"âœ… Clean copy saved to\", DST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8439,
     "status": "ok",
     "timestamp": 1760968500695,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "rypktK_qujmI",
    "outputId": "ea9655e1-c91a-460a-a47f-6a233efd50c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import os, math, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "file_path = \"/content/drive/MyDrive/colab_saves/byday_with_diff_clean.pkl\"\n",
    "df = pd.read_pickle(file_path)\n",
    "df = df[['titles', 'difference']].dropna()\n",
    "df = df[df['titles'].astype(str).str.len() > 0]\n",
    "df = df.drop_duplicates(subset=['titles']).reset_index(drop=True)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "len(train_df), len(val_df), train_df.head(2)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df   = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31472,
     "status": "ok",
     "timestamp": 1760968535244,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "e8JpsRIsvkia",
    "outputId": "34187383-9749-4d15-ad08-c2c1b69e6eb1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2Model(\n",
       "  (embed_tokens): Embedding(151936, 1536)\n",
       "  (layers): ModuleList(\n",
       "    (0-27): 28 x Qwen2DecoderLayer(\n",
       "      (self_attn): Qwen2Attention(\n",
       "        (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "        (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "        (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "      )\n",
       "      (mlp): Qwen2MLP(\n",
       "        (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "        (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "        (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "        (act_fn): SiLUActivation()\n",
       "      )\n",
       "      (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "  (rotary_emb): Qwen2RotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "encoder = AutoModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    dtype=torch.float16,\n",
    "    use_cache=False\n",
    ")\n",
    "\n",
    "\n",
    "if hasattr(encoder, 'gradient_checkpointing_disable'):\n",
    "    encoder.gradient_checkpointing_disable()\n",
    "\n",
    "encoder.to(device).eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1760968554963,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "QD1VXRjIwSQ_"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def mean_pool(last_hidden_state, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).expand_as(last_hidden_state).float()\n",
    "    return (last_hidden_state * mask).sum(dim=1) / torch.clamp(mask.sum(dim=1), 1e-9)\n",
    "\n",
    "class EncoderWithRegHead(nn.Module):\n",
    "    def __init__(self, encoder, hidden_size):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.reg_head = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        last_hidden = out.last_hidden_state\n",
    "        pooled = mean_pool(last_hidden, attention_mask)\n",
    "        pred = self.reg_head(pooled).squeeze(-1)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = nn.MSELoss()(pred, labels)\n",
    "        return {\"loss\": loss, \"logits\": pred}\n",
    "\n",
    "model_core = EncoderWithRegHead(encoder, encoder.config.hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1760968557108,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "-7izIunwGkh_",
    "outputId": "4b85b1f5-8320-4756-827f-a0410c0eecbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,089,536 || all params: 1,544,803,840 || trainable%: 0.0705\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"FEATURE_EXTRACTION\",\n",
    ")\n",
    "\n",
    "\n",
    "model_core.encoder = get_peft_model(model_core.encoder, lora_cfg)\n",
    "\n",
    "\n",
    "if hasattr(model_core.encoder.config, \"use_cache\"):\n",
    "    model_core.encoder.config.use_cache = False\n",
    "\n",
    "\n",
    "model_core.encoder.print_trainable_parameters()\n",
    "\n",
    "\n",
    "model_core = model_core.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1760968558600,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "8lF6LmmVOiOP"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.data.data_collator import DataCollatorMixin\n",
    "from typing import Any, Dict, List\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForRegression(DataCollatorMixin):\n",
    "    tokenizer: Any\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "\n",
    "        labels = [f.pop(\"labels\") for f in features] if \"labels\" in features[0] else None\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=True,\n",
    "            return_tensors=self.return_tensors,\n",
    "        )\n",
    "\n",
    "\n",
    "        if labels is not None:\n",
    "            batch[\"labels\"] = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorForRegression(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1760968669467,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "KvnBulqX6Oaw",
    "outputId": "d582b738-a31a-4574-d6b9-376e611184ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: 413 samples\n",
      "Validation dataset: 104 samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class TitlesRegDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=64, text_col=\"titles\", y_col=\"difference\"):\n",
    "        df = df[[text_col, y_col]].copy()\n",
    "        df[y_col] = pd.to_numeric(df[y_col], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[y_col]).reset_index(drop=True)\n",
    "\n",
    "        self.df = df\n",
    "        self.tk = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.text_col = text_col\n",
    "        self.y_col = y_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = str(row[self.text_col])\n",
    "        y = float(row[self.y_col])\n",
    "\n",
    "        enc = self.tk(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(y, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "\n",
    "train_ds = TitlesRegDataset(train_df, tokenizer, max_len=64)\n",
    "val_ds = TitlesRegDataset(val_df, tokenizer, max_len=64)\n",
    "\n",
    "print(f\"Training dataset: {len(train_ds)} samples\")\n",
    "print(f\"Validation dataset: {len(val_ds)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 960169,
     "status": "ok",
     "timestamp": 1760969631781,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "sch0SDhERjU8",
    "outputId": "2f225915-bcd9-4800-9023-704c8b9cc914"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 09:38, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.149400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>23.889900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=9.415194789568583, metrics={'train_runtime': 959.4888, 'train_samples_per_second': 0.003, 'train_steps_per_second': 0.003, 'total_flos': 0.0, 'train_loss': 9.415194789568583, 'epoch': 0.375})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./out_single\",\n",
    "    max_steps=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=5e-5,\n",
    "    logging_steps=1,\n",
    "    logging_first_step=True,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=False,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=False,\n",
    ")\n",
    "\n",
    "\n",
    "small_train = Subset(train_ds, range(min(8, len(train_ds))))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_core,\n",
    "    args=args,\n",
    "    train_dataset=small_train,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "executionInfo": {
     "elapsed": 1804595,
     "status": "ok",
     "timestamp": 1760972043637,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "zF7sJaWYAWJH",
    "outputId": "77b4c9b4-90ae-4c6c-c223-30fe4f22eb20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "VALIDATION SET METRICS\n",
      "==================================================\n",
      "RMSE (Root Mean Squared Error): 7.1924\n",
      "MAE (Mean Absolute Error):      4.7791\n",
      "RÂ² (R-squared):                 -0.2572\n",
      "==================================================\n",
      "\n",
      "Sample Predictions:\n",
      "--------------------------------------------------\n",
      "Title: ['Hyperscaler demand remains strong despite tariff concerns: Wedbush', 'Some sellers back out of Amazon Prime Day on Trump tariff concerns - report', 'Anthropic joins OpenAI, forms group looking into economic impact of AI', 'Retail blockbuster: Amazon earnings this week could reset expectations across the retail sector', 'What to do about AI, according to BlackRock']...\n",
      "  Actual: -3.71 | Predicted: 2.52\n",
      "\n",
      "Title: ['SoftBank & OpenAI set up an AI focused joint venture in Japan']...\n",
      "  Actual: 1.77 | Predicted: 3.14\n",
      "\n",
      "Title: ['Bill Gates to donate 99% of his remaining fortune to the Gates Foundation; org to close in 2045', 'Silicon Valley execs to push for softer AI regulatory approach in Senate hearing', 'FDA to speed up AI rollout to accelerate drug reviews']...\n",
      "  Actual: 1.83 | Predicted: 3.16\n",
      "\n",
      "Title: ['Waymo continues to expand its robotaxi fleet aggressively']...\n",
      "  Actual: -2.04 | Predicted: 2.55\n",
      "\n",
      "Title: ['Softbank may invest up to $25 billion in OpenAI, eyeing top backer spot - report', 'Microsoft Azure disappoints but AI paves path for revenue growth', \"Microsoft, Meta's plans for AI infrastructure send related stocks surging\", 'OpenAI, U.S. National Labs to advance research using AI models on Nvidia supercomputer', 'OpenAI in talks to raise funds that would value gen AI startup at $340B: report']...\n",
      "  Actual: 3.99 | Predicted: 3.13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "predictions = trainer.predict(val_ds)\n",
    "preds = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "\n",
    "\n",
    "mse = mean_squared_error(labels, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(labels, preds)\n",
    "r2 = r2_score(labels, preds)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"VALIDATION SET METRICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.4f}\")\n",
    "print(f\"MAE (Mean Absolute Error):      {mae:.4f}\")\n",
    "print(f\"RÂ² (R-squared):                 {r2:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(min(5, len(val_df))):\n",
    "    print(f\"Title: {val_df.iloc[i]['titles'][:60]}...\")\n",
    "    print(f\"  Actual: {labels[i]:.2f} | Predicted: {preds[i]:.2f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPoboHmqvSAdud+7jbOh5Ni",
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
