{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 4959,
     "status": "error",
     "timestamp": 1760114834273,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "AbFnrkvCBD6f",
    "outputId": "26d5229a-118e-4221-d1f9-6680f1e13baa"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3379806638.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mSRC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/Untitled20.ipynb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mDST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/colab_saves/LoRA.ipynb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import nbformat, os\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "SRC = '/content/drive/MyDrive/Colab Notebooks/Untitled20.ipynb'\n",
    "DST = '/content/drive/MyDrive/colab_saves/LoRA for prediction.ipynb'\n",
    "\n",
    "with open(SRC, 'r', encoding='utf-8') as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "\n",
    "nb.metadata.pop('widgets', None)\n",
    "for cell in nb.cells:\n",
    "    cell.metadata.pop('widgets', None)\n",
    "os.makedirs(os.path.dirname(DST), exist_ok=True)\n",
    "with open(DST, 'w', encoding='utf-8') as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "print(\"✅ Clean copy saved to\", DST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46890,
     "status": "ok",
     "timestamp": 1760103824005,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "rypktK_qujmI",
    "outputId": "6bb70156-b4c7-4154-a411-42615bfe1598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os, math, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "file_path = \"/content/drive/MyDrive/colab_saves/byday_with_diff_clean.pkl\"\n",
    "df = pd.read_pickle(file_path)\n",
    "df = df[['titles', 'difference']].dropna()\n",
    "df = df[df['titles'].astype(str).str.len() > 0]\n",
    "df = df.drop_duplicates(subset=['titles']).reset_index(drop=True)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "len(train_df), len(val_df), train_df.head(2)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df   = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354,
     "referenced_widgets": [
      "12fe6fd99dfb46e784f5f3b996262a91",
      "5c040c2c8cd44053a7948dca65141a8a",
      "9fbeab4737e0479eaa85f376904b32d5",
      "4546f9f7251e4618a0d5e37f1980e480",
      "90b2cfcaad234d2fb83257b29b0d82c1",
      "b921cbfa8cf54875a858175459c1c949",
      "41e548997be2492ca654b95fa995c8e8",
      "ee9e6c81469940d98432e74581c2ddcd",
      "bae9fd8ca866459bb364923e3472fa51",
      "30f14e6311cd4d3f934e7b2160420814",
      "f6da33d7ddce4d13ac16e3eb235186d5",
      "c4dd8a9c403c4e50b47ef8565600e529",
      "b6cbd896cdaa4dde9aa60ab2734b640e",
      "922c3bc211fa4d128372387bb138a4d9",
      "096e02995fab44bebe7d26733d778b4d",
      "9a37451272d942789084b623fdb6b3c6",
      "0419e97cde664d73bae5159a8d35ebae",
      "b15412971eb84203be127261c4f16fd7",
      "01337ee03d8d41a19076bf10e48a2060",
      "5af71319da3a4aa5a57f10d84827eac7",
      "f869015ac7f145d0a5c37300fe626d5a",
      "1e0156f931294ca593399d89ea035b29",
      "12abd61e5d91403e8b378526878ead6f",
      "8c64d079c4ae494e914a586da0dc92ab",
      "83128f7a11b54633b57dcb53527bb1d5",
      "e2c519bf22b745d49b3c0ba87a88debb",
      "9a5f7a7b179444e49701a7c8d82062fd",
      "f96f86ce6c5a4e6b9706879fbd5966e8",
      "ae568881a8324a2583630ea73948a8e7",
      "8a80fb21f25241d7b2e751d962989a82",
      "1804effd54d844389fa678a79036fcf7",
      "134c5005d87545e9a6ea4adde67ae2e4",
      "dc1f0f2ebe9c41539f88e1256c12a2a9",
      "43a0be5bf9864997997db44456367ac3",
      "4b28235b80cb4bdab8a7f46ac626888e",
      "0102e3b36fed4b499a5f35c74e65c31f",
      "cf520eae47d140fda22a513498420346",
      "fbcf247982954bf29b1ac31761ff8263",
      "72c74e501976410c89fa5981f11cb634",
      "2c6b372110d34c048658b2a92c7f91d2",
      "b1a7d6d825c04c568e88cd4d28e0bac0",
      "0fcc2f33aee54e27bd8836d2eaf38c8d",
      "eba24bb6560a4bcfb8830063651e3a26",
      "6738b61e84f94aeca2ca17d42f8f17c2",
      "9b1a1964c83840deb90c6881c0cdb1ed",
      "a768bc81a196438f9f84155a8b6d6328",
      "69ca08b4df7f41b7b55fd2ad2d0482fb",
      "d9b708cdd4494d6bab5e26695cad3378",
      "4efc40e658154697a4fd966218715def",
      "ff1e855ca6f84d98b69f7c4b4630ae37",
      "7874af448b3e4123b78b2c0212b88b30",
      "52ffb1bc299f4181a2e2622210375457",
      "af7cbf6ed62e496cbb14fdca3a11e482",
      "cf1d9840856549db9ce7b926eaf8e780",
      "542df3f9c7594508956994a060f3d76a",
      "8034691b10c84b4abde5fa0c2777d372",
      "5963bcd1e6bb449a8e488b343fdc5bcc",
      "6648730d09c342cda50855c119d9e612",
      "3d5ad9e7e52a4ee2b584e73e76cfc2a6",
      "50a47ab1708c40b6bebb610b87649e4d",
      "1dcd4d75536b4c75aa9452cde0b8936b",
      "3116f625be8f4331b41a5f03693bf8a7",
      "3fa81e5918ad495cb6e9d6f7a47392e6",
      "021424c3134b490795050f90e06308f6",
      "8f7a913f52934f3ba87f41c6f60e5840",
      "a2c505b526be4d599be9674a1211b53d"
     ]
    },
    "executionInfo": {
     "elapsed": 42918,
     "status": "ok",
     "timestamp": 1760103866920,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "e8JpsRIsvkia",
    "outputId": "6c66c989-d7eb-4672-c36c-51f73e54b6a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12fe6fd99dfb46e784f5f3b996262a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4dd8a9c403c4e50b47ef8565600e529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12abd61e5d91403e8b378526878ead6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a0be5bf9864997997db44456367ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1a1964c83840deb90c6881c0cdb1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8034691b10c84b4abde5fa0c2777d372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "base_model = AutoModel.from_pretrained(MODEL_NAME, torch_dtype=dtype)\n",
    "\n",
    "\n",
    "if hasattr(base_model.config, \"use_cache\"):\n",
    "    base_model.config.use_cache = False\n",
    "hidden_size = base_model.config.hidden_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1760103866938,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "QD1VXRjIwSQ_"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch, torch.nn as nn\n",
    "\n",
    "def mean_pool(last_hidden_state, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).expand_as(last_hidden_state).float()\n",
    "    summed = (last_hidden_state * mask).sum(dim=1)\n",
    "    counts = torch.clamp(mask.sum(dim=1), min=1e-9)\n",
    "    return summed / counts\n",
    "\n",
    "class EncoderWithRegHead(nn.Module):\n",
    "    def __init__(self, encoder, hidden_size):\n",
    "        super().__init__()\n",
    "        self.encoder  = encoder\n",
    "        self.reg_head = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        out = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "        last_hidden = out.last_hidden_state\n",
    "        pooled = mean_pool(last_hidden, attention_mask)\n",
    "        pred = self.reg_head(pooled).squeeze(-1)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = nn.MSELoss()(pred, labels)\n",
    "        return {\"loss\": loss, \"logits\": pred}\n",
    "\n",
    "\n",
    "model_core = EncoderWithRegHead(base_model, base_model.config.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1760103866950,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "-7izIunwGkh_"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "class TitlesRegDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, tokenizer, max_len: int = 64, text_col: str = \"titles\", y_col: str = \"difference\"):\n",
    "        df = df[[text_col, y_col]].copy()\n",
    "        df[y_col] = pd.to_numeric(df[y_col], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[y_col]).reset_index(drop=True)\n",
    "\n",
    "        self.df = df\n",
    "        self.tk = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.text_col = text_col\n",
    "        self.y_col = y_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = str(row[self.text_col])\n",
    "        y    = float(row[self.y_col])\n",
    "\n",
    "        enc = self.tk(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(y, dtype=torch.float)\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1760103866962,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "ICf5k8_-FX0K"
   },
   "outputs": [],
   "source": [
    "train_ds = TitlesRegDataset(train_df, tokenizer, max_len=64)\n",
    "val_ds   = TitlesRegDataset(val_df, tokenizer, max_len=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 808,
     "status": "ok",
     "timestamp": 1760103867771,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "YTwFs7QiwhTd",
    "outputId": "68242abb-b60b-4122-9a92-a6f4b51c3734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has last_hidden_state: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    task_type=TaskType.FEATURE_EXTRACTION,\n",
    "    r=2,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    ")\n",
    "model_core.encoder = get_peft_model(model_core.encoder, lora_cfg)\n",
    "\n",
    "\n",
    "if hasattr(model_core.encoder.config, \"use_cache\"):\n",
    "    model_core.encoder.config.use_cache = False\n",
    "if hasattr(model_core.encoder, \"gradient_checkpointing_enable\"):\n",
    "    model_core.encoder.gradient_checkpointing_enable()\n",
    "    if hasattr(model_core.encoder, \"enable_input_require_grads\"):\n",
    "        model_core.encoder.enable_input_require_grads()\n",
    ")\n",
    "with torch.no_grad():\n",
    "    enc = tokenizer(\"test\", return_tensors=\"pt\")\n",
    "    out = model_core.encoder(**enc, return_dict=True)\n",
    "    print(\"Has last_hidden_state:\", hasattr(out, \"last_hidden_state\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1760103867847,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "njwAeJM6z5po"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UMcuuBeBfYJ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17884,
     "status": "ok",
     "timestamp": 1760103954247,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "u2yIjXqYXqjt",
    "outputId": "d052741c-0711-416c-cc23-53f4e44d6113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.35.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "6ce68da14a5b463c8164d5c5351790ca",
      "38e29a72ead147008f5b2f15ea990669",
      "19cec7fd49814c1a9e8bc35dc36bc79d",
      "ed88d74df7c64ab29291761e30e1181d",
      "3e9ad54dfef04a6da4bfc5347a67abc3",
      "545128bc17d648749b67010a65574fbd",
      "47c2b72ce106414fbf70a30cdbea9654",
      "17a31a86fe8a4dfba1af800343ef49da",
      "524466b762d94d759fd92c8e2fda4d37",
      "302534383b11480c9f6e4786b8882f12",
      "aafdc05519e844e4a5471584322dc72f",
      "750dd1c359124d2b91c45706b806fa8c",
      "0a02addd53294958b87d8b204cbc90cd",
      "8c90a2f499924b8ebb2abf4942488530",
      "69b28ed7e64d4ba886c8f6d4e53ca77f",
      "aa5df08cf7d84372bbaccae7f98e7e71",
      "f1b51e923a024fde917fd3a718e133b0",
      "57ed704988ed4495bccbe1191f773a33",
      "2793e6daa522423d93523cf0adf51b4c",
      "f552bb8729734ccb8f7195cb88739180",
      "c511f26e2d244bcdb0e738daf34057e8",
      "b0b43e0d5e1949b6bc1b5390c8148591"
     ]
    },
    "executionInfo": {
     "elapsed": 7804,
     "status": "ok",
     "timestamp": 1760103967061,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "ElwmuCr5wtFD",
    "outputId": "8b67a4cd-1280-45b8-a563-92a8f3820ed3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce68da14a5b463c8164d5c5351790ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750dd1c359124d2b91c45706b806fa8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "mse_metric = evaluate.load(\"mse\")\n",
    "mae_metric = evaluate.load(\"mae\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = preds.reshape(-1)\n",
    "    labels = labels.reshape(-1)\n",
    "    mse = mse_metric.compute(predictions=preds, references=labels)[\"mse\"]\n",
    "    mae = mae_metric.compute(predictions=preds, references=labels)[\"mae\"]\n",
    "    rmse = np.sqrt(mse)\n",
    "    ybar = labels.mean()\n",
    "    ss_res = float(((labels - preds) ** 2).sum())\n",
    "    ss_tot = float(((labels - ybar) ** 2).sum()) + 1e-12\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return {\"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1760103970446,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "b-v3Yrhhyo_F"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "MAX_LEN = 48\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "import torch\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_news_reg\",\n",
    "    learning_rate=8e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.0,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "\n",
    "\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=False,\n",
    "    remove_unused_columns=False,\n",
    "\n",
    "    gradient_checkpointing=False,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    "    logging_steps=25,\n",
    "    max_steps=200,\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "executionInfo": {
     "elapsed": 2087026,
     "status": "ok",
     "timestamp": 1760108172465,
     "user": {
      "displayName": "Peng",
      "userId": "11558679983686850100"
     },
     "user_tz": -60
    },
    "id": "E9urJlEDyGcY",
    "outputId": "1939448e-5fff-4160-c3ff-d26471affc83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-515510732.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 33:06, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>6.799100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>12.278500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>9.927400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.940100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>10.121900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>7.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>9.592100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>6.244400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 01:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 40.75928497314453, 'eval_rmse': 6.384300544828414, 'eval_mae': 3.5156502577547846, 'eval_r2': 0.009425254909084635, 'eval_runtime': 80.1368, 'eval_samples_per_second': 1.298, 'eval_steps_per_second': 0.649, 'epoch': 1.9297820823244551}\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_core,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "import torch\n",
    "with torch.no_grad():\n",
    "    metrics = trainer.evaluate()\n",
    "print(metrics)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAugmToktMIpC90d5bRKr8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
